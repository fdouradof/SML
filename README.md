{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPijU+O61zuplsQVj4GfiNf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fdouradof/SML/blob/main/Teacherbot_Wikipedia_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysLFoPNKO-yn",
        "outputId": "2de40539-6daf-4400-8a8c-ce4264de6a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import openpyxl\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def dore(reg_exp, my_text):\n",
        "    result = []\n",
        "    reg_exp_compiled = re.compile(reg_exp)\n",
        "    for i in range(len(my_text)):\n",
        "        if reg_exp_compiled.search(my_text[i]):\n",
        "            result.append(my_text[i])\n",
        "    return result\n",
        "\n",
        "\n",
        "def catalog(soup,subjs):\n",
        "    url_links = []\n",
        "    url_texts = []\n",
        "    for link in soup.find_all(\"a\"):\n",
        "        url = link.get(\"href\", \"\")                  # escolhe os SIZE primeiros links\n",
        "        for subject in subjs:\n",
        "            if subject in url.lower() and len(url_links) < SIZE+1:\n",
        "                # print(subject)\n",
        "                url_links.append(url)\n",
        "                url_texts.append(link.text.strip())\n",
        "    catalogue = pd.DataFrame({\"Title\": url_texts, \"Link\": url_links})\n",
        "    print(catalogue)\n",
        "    return catalogue\n",
        "def wiki_reader(df,kws):\n",
        "    df = df.drop_duplicates()\n",
        "    data = []\n",
        "    for k in range(len(df)):\n",
        "        url = \"https://en.wikipedia.org\" + df.iloc[k][\"Link\"]\n",
        "        try:\n",
        "            page = requests.get(url)\n",
        "        except:\n",
        "            continue\n",
        "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "        page_title = soup.find(\"span\", class_=\"mw-page-title-main\")\n",
        "        page_texts = soup.find_all(\"p\")\n",
        "        # print(\"Analizing Page title:     \", page_title.text)\n",
        "\n",
        "        bagparag = []\n",
        "        keys = []\n",
        "        result = []\n",
        "        for paragraph in page_texts:\n",
        "            tk_parag = nltk.word_tokenize(paragraph.text)\n",
        "            for kw in kws:\n",
        "                if kw in tk_parag:\n",
        "                    bagparag.append(tk_parag)\n",
        "                    # sentences = nltk.word_tokenize(paragraph.text)\n",
        "                    sentences = nltk.sent_tokenize(paragraph.text)\n",
        "                    for i in range(len(sentences)):\n",
        "                        sentences[i] = sentences[i].lower()\n",
        "                        sentences[i] = re.sub(r'[^A-Za-z0-9,. ]+', ' ',sentences[i])\n",
        "                        sentences[i] = re.sub(r'\\W', ' ',sentences[i])  # Substitute the non-alphanumeric characters with space.\n",
        "                        sentences[i] = re.sub(r'\\s+', ' ', sentences[i])  # Remove the excess of white spaces.\n",
        "                        sentences[i] = re.sub(r'\\s$', '', sentences[i])  # Remove the space at the end of a sentence.\n",
        "                        sentences[i] = re.sub(r'also', '', sentences[i])\n",
        "                    for i in range(len(sentences)):\n",
        "                        bparag = nltk.word_tokenize(sentences[i])  # Tokenize into words.\n",
        "                        bparag = [x for x in bparag if x not in stopwords.words('english')]  # Remove the stop words.\n",
        "                        sentences[i] = ' '.join(bparag)\n",
        "                    keys.append(kw)\n",
        "                    result.append(sentences)\n",
        "\n",
        "        if len(bagparag) > 2:\n",
        "            X, key_words = ti(result)\n",
        "            data.append((page_title,url,result,key_words,X,keys))\n",
        "            #print(\"paragraphs matches: \", len(bagparag))\n",
        "        # print(\"-------------------------------------\")\n",
        "    DATA = pd.DataFrame(data, columns=[\"title\",\"url\", \"words\", \"keywords\", \"TI\",\"match\"])\n",
        "    return DATA\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ti(docs):\n",
        "    docs = [str(x).lower() for x in docs]\n",
        "    vectorizer = TfidfVectorizer(max_features=10, min_df=0.01, max_df=0.99, stop_words=stopwords.words('english'))\n",
        "    X = vectorizer.fit_transform(docs).toarray()\n",
        "    key_words = vectorizer.get_feature_names_out()\n",
        "    return X, key_words\n",
        "    \n",
        "def Vectorizer(docs):\n",
        "    X,kw = ti(docs)\n",
        "    Count_vect = CountVectorizer(max_df = 0.9, min_df  = 0.1, max_features = 10 )\n",
        "    t = df.head(40).astype(str)[\"words\"]\n",
        "    vectors = Count_vect.fit_transform(t)\n",
        "    features = Count_vect.get_feature_names_out()\n",
        "    dense = vectors.todense()\n",
        "    denselist = dense.tolist()\n",
        "    TF = pd.DataFrame(denselist, columns = features, index = df[\"title\"])\n",
        "    return X, kw, TF"
      ],
      "metadata": {
        "id": "j3lZfUm-8VR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rollup(df,position):\n",
        "  MAX_SUBJS = 3\n",
        "  new_subjs = []\n",
        "\n",
        "  X, kws, TF = Vectorizer(df[\"match\"])\n",
        "  sorted = TF.sum(axis= 1).sort_values().index\n",
        "  for i in range(MAX_SUBJS):\n",
        "    tt = nltk.word_tokenize(sorted[-(i+1)].text)\n",
        "    tt = [x for x in tt if x not in stopwords.words('english')]  # Remove the stop words.\n",
        "    new_subjs = list(new_subjs) + list(tt)\n",
        "    new_subjs = np.unique(new_subjs)\n",
        "  new_url = df.mask(df[\"title\"] != sorted[-1*position]).dropna()[\"url\"].iloc[0]\n",
        "  return new_url, new_subjs\n"
      ],
      "metadata": {
        "id": "1dh3-jQmWXqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 10 + 3 \n",
        "\n",
        "'''ESCOLHA AQUI A URL '''\n",
        "# url = \"https://en.wikipedia.org/wiki/Chemistry\"\n",
        "url = \"https://en.wikipedia.org/wiki/Physics\"\n",
        "# url = \"https://en.wikipedia.org/wiki/Geography\"\n",
        "\n",
        "''' AQUI AS PALAVRAS CHAVES PARA A BUSCA'''\n",
        "subjects = [\"biology\",\"chemistry\",\"physics\"]\n",
        "#subjects = [\"science\",\"philosophy\"]\n",
        "key_words = [\"mechanical\", \"science\", \"scientific\", \"philosophy\",\"quantum\",\"particle\"]\n",
        "\n",
        "\"\"\"O MODULO REQUESTS LE O SITE\"\"\"\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "\"\"\"TEACHER BOT le os sites\"\"\"\n",
        "catalog1 = catalog(soup,subjects)\n",
        "df = wiki_reader(catalog1,key_words)\n"
      ],
      "metadata": {
        "id": "XftgIcuYRhEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.head(2))"
      ],
      "metadata": {
        "id": "BPobIgxXSffL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "692e4f19-1381-440d-8181-bc1249d35086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  title                                               url  \\\n",
              "0  [Outline of physics]  https://en.wikipedia.org/wiki/Outline_of_physics   \n",
              "1  [History of physics]  https://en.wikipedia.org/wiki/History_of_physics   \n",
              "\n",
              "                                               words  \\\n",
              "0  [[physics natural science involves study matte...   \n",
              "1  [[physics branch science whose primary objects...   \n",
              "\n",
              "                                            keywords  \\\n",
              "0  [fundamental, include, matter, motion, particl...   \n",
              "1  [huygens, mechanics, motion, new, newton, phys...   \n",
              "\n",
              "                                                  TI  \\\n",
              "0  [[0.0, 0.0, 0.4472135954999579, 0.447213595499...   \n",
              "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.9823269828769735,...   \n",
              "\n",
              "                                               match  \n",
              "0              [science, science, science, particle]  \n",
              "1  [science, philosophy, scientific, philosophy, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9bdc2ab-0a4a-45b5-874c-ece0104b1740\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>words</th>\n",
              "      <th>keywords</th>\n",
              "      <th>TI</th>\n",
              "      <th>match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Outline of physics]</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Outline_of_physics</td>\n",
              "      <td>[[physics natural science involves study matte...</td>\n",
              "      <td>[fundamental, include, matter, motion, particl...</td>\n",
              "      <td>[[0.0, 0.0, 0.4472135954999579, 0.447213595499...</td>\n",
              "      <td>[science, science, science, particle]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[History of physics]</td>\n",
              "      <td>https://en.wikipedia.org/wiki/History_of_physics</td>\n",
              "      <td>[[physics branch science whose primary objects...</td>\n",
              "      <td>[huygens, mechanics, motion, new, newton, phys...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.9823269828769735,...</td>\n",
              "      <td>[science, philosophy, scientific, philosophy, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9bdc2ab-0a4a-45b5-874c-ece0104b1740')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9bdc2ab-0a4a-45b5-874c-ece0104b1740 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9bdc2ab-0a4a-45b5-874c-ece0104b1740');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "searches = []\n",
        "visited = [url]\n",
        "\n",
        "X, new_kws, TF = Vectorizer(df[\"match\"])\n",
        "sresult = (df,X,new_kws)\n",
        "searches.append(sresult)\n",
        "\n",
        "\n",
        "  visited.append(new_url)\n",
        "  requests.get(new_url)\n",
        "  new_soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "  new_catalog = catalog(new_soup,subjects)\n",
        "  df = wiki_reader(new_catalog,new_kws)\n",
        "  X, new_kws, TF = Vectorizer(df[\"match\"])\n",
        "  sresult = (df,X,new_kws)\n",
        "  searches.append(sresult)\n",
        "\n",
        "\n",
        "# display(TF)"
      ],
      "metadata": {
        "id": "BEGpj7eLTUxH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
