{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP38ZnwPDgUXZpa4ye/vx7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fdouradof/SML/blob/main/TeacherBot_Interface%20V1.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Usm2lJRcRr3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1edc22b-84ca-47f3-923b-95c4a9254ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import json, time, os\n",
        "import numpy as np\n",
        "import openpyxl\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def Tfid(docs):\n",
        "    \"\"\" Receive list of strings\n",
        "        returns list of term frequency matrices for each string in previous list\n",
        "        returns also list of keywords\"\"\"\n",
        "\n",
        "    docs = [str(x).lower() for x in docs]\n",
        "    vectorizer = TfidfVectorizer(max_features=10, min_df=0.01, max_df=0.99, stop_words=stopwords.words('english'))\n",
        "    X = vectorizer.fit_transform(docs).toarray()\n",
        "    key_words = vectorizer.get_feature_names_out()\n",
        "    return X, key_words\n",
        "\n",
        "def catalog(url,subjects):\n",
        "    \"\"\" Receives URL and returns list of links as pandas dataframe\n",
        "        links must have title matching a subject \"\"\"\n",
        "    url_links = []\n",
        "    url_texts = []\n",
        "    SIZE = 50\n",
        "    \n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "    for link in soup.find_all(\"a\"):\n",
        "        url = link.get(\"href\", \"\")                                       #html reference for hyperlinks\n",
        "        for subject in subjects:                                         # test for each subject in list\n",
        "            if subject in url.lower() and len(url_links) < SIZE+1:        # find a maximum of SIZE matches \n",
        "                url_links.append(url)\n",
        "                url_texts.append(link.text.strip())\n",
        "    \n",
        "    catalogue = pd.DataFrame({\"Title\": url_texts, \"Link\": url_links})\n",
        "    return catalogue\n",
        "\n",
        "def wiki_reader(catalog,kws):\n",
        "    \n",
        "    \"\"\"NEED FIXING THE DUPLICATES BEING ADDED DO DF\"\"\"\n",
        "    \n",
        "    \"\"\"\"reads links from Catalog dataframe\n",
        "        find paragraphs on links with matches from kws\n",
        "        returns name of page, kw match, regex treated text and tfid with keywords\n",
        "        as pandas dataframe\n",
        "    \"\"\"\n",
        "    catalog = catalog.drop_duplicates()              # dont visit sites more than once\n",
        "    data = []\n",
        "    keys = []\n",
        "    matched = False\n",
        "    for k in range(len(catalog)):\n",
        "        url = \"https://en.wikipedia.org\" + catalog.iloc[k][\"Link\"]\n",
        "        try:\n",
        "          # some urls dont work\n",
        "          page = requests.get(url)\n",
        "          soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "          # if dont find anything returns noneytype \n",
        "          page_title = soup.find(\"span\", class_=\"mw-page-title-main\")\n",
        "          page_texts = soup.find_all(\"p\")\n",
        "          print(\"Analizing Page title:     \", page_title.text)\n",
        "      \n",
        "          for paragraph in page_texts:\n",
        "              rg_parag = dore(paragraph)\n",
        "              tk_parag = nltk.word_tokenize(paragraph.text)\n",
        "              for kw in kws:\n",
        "                  if kw in tk_parag:\n",
        "                      matched = True\n",
        "                      key_found = kw\n",
        "              if matched:\n",
        "                  try:\n",
        "                      X, key_words = Tfid(tk_parag)\n",
        "                      data.append((page_title, rg_parag, key_words, X, keys))\n",
        "                      keys.append(key_found)\n",
        "                  except:\n",
        "                      pass\n",
        "        except:\n",
        "            continue\n",
        "            \n",
        "    DATA = pd.DataFrame(data, columns=[\"page_title\", \"page_text\", \"keywords\", \"tfid\",\"match\"])\n",
        "    return DATA\n",
        "\n",
        "def dore(paragraph):\n",
        "\n",
        "    \"\"\" receives one or more sentences in one string\n",
        "        returns the clean sentences joined by a space\n",
        "    \"\"\"\n",
        "    joined_sentences = []\n",
        "    sentences = nltk.sent_tokenize(paragraph.text)\n",
        "    for i in range(len(sentences)):\n",
        "        sentences[i] = sentences[i].lower()\n",
        "        sentences[i] = re.sub(r'[^A-Za-z0-9,. ]+', ' ', sentences[i])\n",
        "        sentences[i] = re.sub(r'\\W', ' ', sentences[i])  # Substitute the non-alphanumeric characters with space.\n",
        "        sentences[i] = re.sub(r'\\s+', ' ', sentences[i])  # Remove the excess of white spaces.\n",
        "        sentences[i] = re.sub(r'\\s$', '', sentences[i])  # Remove the space at the end of a sentence.\n",
        "        sentences[i] = re.sub(r'also', '', sentences[i])\n",
        "        sentences[i] = re.sub(r'displaystyle', '', sentences[i])\n",
        "        sentences[i] = re.sub(r',', '', sentences[i])\n",
        "        sentences[i] = re.sub(r'also', '', sentences[i])\n",
        "    for i in range(len(sentences)):\n",
        "        sentences[i] = nltk.word_tokenize(sentences[i])  # Tokenize into words.\n",
        "        sentences[i] = [x for x in sentences[i] if x not in stopwords.words('english')]  # Remove the stop words.\n",
        "        sentences[i] = ' '.join(sentences[i])\n",
        "    joined_sentences.append(sentences)\n",
        "    return joined_sentences\n",
        "def Google(query):\n",
        "    \"\"\"Get first 10 results from query and return a pandas dataframe with\n",
        "            'title'\n",
        "            \"URL\"\n",
        "            'snippet\n",
        "            \"Long description\n",
        "        API allows for more options if needed\n",
        "\"\"\"\n",
        "    google_data = []\n",
        "    API_KEY = \"AIzaSyBO5ZaX_GdfgkYCILF18h4p601JhBzetco\"\n",
        "    SEARCH_ENGINE_ID = \"82bccba347bf948a3\"\n",
        "    # SEARCH_ENGINE_ID = \"8606138438d1d4ebc\" # Secondary ID if needed\n",
        "    page = 1\n",
        "    start = (page - 1) * 10 + 1\n",
        "    url = f\"https://www.googleapis.com/customsearch/v1?key={API_KEY}&cx={SEARCH_ENGINE_ID}&q={query}&start={start}\"\n",
        "    data = requests.get(url).json()\n",
        "    search_items = data.get(\"items\")\n",
        "    for i, search_item in enumerate(search_items, start=1): # when error here means that API reached short/long term limit\n",
        "        try:\n",
        "            long_description = search_item[\"pagemap\"][\"metatags\"][0][\"og:description\"]\n",
        "        except KeyError:\n",
        "            long_description = \"N/A\"\n",
        "        title = search_item.get(\"title\")\n",
        "        snippet = search_item.get(\"snippet\")\n",
        "        link = search_item.get(\"link\")\n",
        "        google_data.append({\n",
        "            'title': title,\n",
        "            \"URL\": link,\n",
        "            'snippet': snippet,\n",
        "            \"long description\": long_description,\n",
        "        })\n",
        "    search_result = pd.read_json(json.dumps(google_data, indent=2, ensure_ascii=False))\n",
        "    return search_result\n",
        "\n",
        "def save_results(search_results):\n",
        "    \"\"\"save result as tuple in all_searches list\"\"\"\n",
        "    \"\"\"BROKEN\"\"\"\n",
        "    X, data_kws = Tfid(search_results[\"page_text\"])\n",
        "    print(\"PESQUISA EM\", url, \"KWS\", data_kws)\n",
        "    sresult = (search_results, X, data_kws)\n",
        "    all_searches.append(sresult)\n",
        "    print(\"PESQUISA GUARDADA\")\n",
        "    return all_searches\n",
        "def update_with_google(pesquisa,all_searches):\n",
        "    \"\"\"building\"\"\"\n",
        "    for i in range(1):\n",
        "        x, kws = Tfid(pesquisa[\"snippet\"])\n",
        "        new_subjects = kws\n",
        "        print(\"USED KEYS\", kws)\n",
        "        catalog2 = catalog(url,new_subjects)\n",
        "        search_data = wiki_reader(catalog2,KEYWORDS)\n",
        "        all_searches = save_results(search_data)\n",
        "    return all_searches\n",
        "def update_with_wiki(search_data):\n",
        "    \"\"\"building\"\"\"\n",
        "    for i in range(2):\n",
        "        print(\"NOVAS CHAVES\", search_data[\"keywords\"][0])\n",
        "        new_subjects = search_data[\"keywords\"][0]\n",
        "        catalog2 = catalog(url,new_subjects)\n",
        "        search_data = wiki_reader(catalog2,KEYWORDS)\n",
        "        all_searches = save_results(search_data)\n",
        "    return all_searches\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "START_WORD = \"chemistry\"\n",
        "SUBJECTS = [\"biology\",\"chemistry\",\"physics\",\"engineering\"]\n",
        "KEYWORDS = [\"mechanical\", \"science\", \"scientific\",\"quantum\",\"particle\"]"
      ],
      "metadata": {
        "id": "aq6sGtuaR3JP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pesquisa = Google(\"branches of \" + START_WORD) não funciona pelo  Collab\n",
        "# Esta célula demora mais a correr \n",
        "url = \"https://en.wikipedia.org/wiki/\" + START_WORD.lower()\n",
        "catalog1 = catalog(url, SUBJECTS)\n",
        "search_data = wiki_reader(catalog1, KEYWORDS)\n"
      ],
      "metadata": {
        "id": "9R-Aeh4qR33j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b21a569-086d-4bfc-f9d1-5fe4da1ab333"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analizing Page title:      Chemistry (disambiguation)\n",
            "Analizing Page title:      Index of chemistry articles\n",
            "Analizing Page title:      Outline of chemistry\n",
            "Analizing Page title:      Glossary of chemistry terms\n",
            "Analizing Page title:      History of chemistry\n",
            "Analizing Page title:      Timeline of chemistry\n",
            "Analizing Page title:      Analytical chemistry\n",
            "Analizing Page title:      Biochemistry\n",
            "Analizing Page title:      Organic chemistry\n",
            "Analizing Page title:      Inorganic chemistry\n",
            "Analizing Page title:      Physical chemistry\n",
            "Analizing Page title:      List of chemistry awards\n",
            "Analizing Page title:      List of chemistry journals\n",
            "Analizing Page title:      List of unsolved problems in chemistry\n",
            "Analizing Page title:      Chemistry\n",
            "Analizing Page title:      Chemistry\n",
            "Analizing Page title:      TopicTOC-Chemistry\n",
            "Analizing Page title:      TopicTOC-Chemistry\n",
            "Analizing Page title:      Physics\n",
            "Analizing Page title:      Biology\n",
            "Analizing Page title:      Cosmochemistry\n",
            "Analizing Page title:      International Union of Pure and Applied Chemistry\n",
            "Analizing Page title:      Radical (chemistry)\n",
            "Analizing Page title:      Solution (chemistry)\n",
            "Analizing Page title:      Plasma (physics)\n",
            "Analizing Page title:      Classical physics\n",
            "Analizing Page title:      Coordination complex\n",
            "Analizing Page title:      Photochemistry\n",
            "Analizing Page title:      Quantization (physics)\n",
            "Analizing Page title:      Dissociation (chemistry)\n",
            "Analizing Page title:      Neutralization (chemistry)\n",
            "Analizing Page title:      Salt (chemistry)\n",
            "Analizing Page title:      Plasma (physics)\n",
            "Analizing Page title:      Base (chemistry)\n",
            "Analizing Page title:      Nuclear chemistry\n",
            "Analizing Page title:      History of chemistry\n",
            "Analizing Page title:      History of chemistry\n",
            "Analizing Page title:      Timeline of chemistry\n",
            "Analizing Page title:      Alchemy in the medieval Islamic world\n",
            "Analizing Page title:      Organic chemistry\n",
            "Analizing Page title:      Outline of chemistry\n",
            "Analizing Page title:      Chemistry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(search_data.head(5))\n",
        "#needs to fix duplicates being added  in tittles and in keyword for tfid name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "-nV6PdWeR5fi",
        "outputId": "7349dd06-a2e2-4bff-ff3c-66381cfdbec8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                      page_title  \\\n",
              "0   [Chemistry (disambiguation)]   \n",
              "1   [Chemistry (disambiguation)]   \n",
              "2  [Index of chemistry articles]   \n",
              "3  [Index of chemistry articles]   \n",
              "4         [Outline of chemistry]   \n",
              "\n",
              "                                           page_text  \\\n",
              "0  [[chemistry branch physical science study subs...   \n",
              "1                            [[chemistry may refer]]   \n",
              "2  [[chemistry egyptian k chem meaning earth 1 ph...   \n",
              "3  [[list chemistry related articles, chemical co...   \n",
              "4  [[following outline provided overview topical ...   \n",
              "\n",
              "                                            keywords  \\\n",
              "0  [branch, chemistry, composed, matter, physical...   \n",
              "1                      [also, chemistry, may, refer]   \n",
              "2  [changes, egyptian, kēme, matter, meaning, phy...   \n",
              "3  [articles, biomolecules, chemical, chemistry, ...   \n",
              "4  [chemistry, following, guide, outline, overvie...   \n",
              "\n",
              "                                                tfid  \\\n",
              "0  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
              "1  [[0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [...   \n",
              "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
              "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
              "4  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1....   \n",
              "\n",
              "                                               match  \n",
              "0  [science, science, science, science, science, ...  \n",
              "1  [science, science, science, science, science, ...  \n",
              "2  [science, science, science, science, science, ...  \n",
              "3  [science, science, science, science, science, ...  \n",
              "4  [science, science, science, science, science, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa3a03d2-8d8d-411c-8ed8-666abbb56756\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_title</th>\n",
              "      <th>page_text</th>\n",
              "      <th>keywords</th>\n",
              "      <th>tfid</th>\n",
              "      <th>match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Chemistry (disambiguation)]</td>\n",
              "      <td>[[chemistry branch physical science study subs...</td>\n",
              "      <td>[branch, chemistry, composed, matter, physical...</td>\n",
              "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[science, science, science, science, science, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Chemistry (disambiguation)]</td>\n",
              "      <td>[[chemistry may refer]]</td>\n",
              "      <td>[also, chemistry, may, refer]</td>\n",
              "      <td>[[0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [...</td>\n",
              "      <td>[science, science, science, science, science, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[Index of chemistry articles]</td>\n",
              "      <td>[[chemistry egyptian k chem meaning earth 1 ph...</td>\n",
              "      <td>[changes, egyptian, kēme, matter, meaning, phy...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[science, science, science, science, science, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Index of chemistry articles]</td>\n",
              "      <td>[[list chemistry related articles, chemical co...</td>\n",
              "      <td>[articles, biomolecules, chemical, chemistry, ...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[science, science, science, science, science, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Outline of chemistry]</td>\n",
              "      <td>[[following outline provided overview topical ...</td>\n",
              "      <td>[chemistry, following, guide, outline, overvie...</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1....</td>\n",
              "      <td>[science, science, science, science, science, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa3a03d2-8d8d-411c-8ed8-666abbb56756')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa3a03d2-8d8d-411c-8ed8-666abbb56756 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa3a03d2-8d8d-411c-8ed8-666abbb56756');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6VsAhcwApfF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}